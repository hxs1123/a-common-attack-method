import os
import torch
from tqdm import tqdm
import numpy as np
from tqdm.auto import tqdm


# ----------------------------------------------------------------
#   ä¿å­˜æ¨¡å‹çš„çŠ¶æ€
# ----------------------------------------------------------------
def save_checkpoint(model, optimizer, epoch, clean_acc, poison_success, file_path="vilt_vqa_checkpoint.pth"):
    """ä¿å­˜æ¨¡å‹è®­ç»ƒçŠ¶æ€"""
    checkpoint = {
        "epoch": epoch,
        "model_state_dict": model.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
        "best_clean_acc": clean_acc,
        "best_poison_success": poison_success,
    }
    torch.save(checkpoint, file_path)
    print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: Epoch {epoch+1}")


# ------------------------------------------------------------------
#    åŠ è½½æ¨¡å‹çš„çŠ¶æ€
# ------------------------------------------------------------------
def load_checkpoint(model, optimizer, file_path="vilt_vqa_checkpoint.pth"):
    """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹è®­ç»ƒçŠ¶æ€"""
    if os.path.exists(file_path):
        checkpoint = torch.load(file_path)
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        epoch = checkpoint["epoch"]
        best_clean_acc = checkpoint["best_clean_acc"]
        best_poison_success = checkpoint["best_poison_success"]
        print(f"âœ… å·²æ¢å¤è®­ç»ƒ: ä» Epoch {epoch+1} ç»§ç»­")
        return epoch, best_clean_acc, best_poison_success
    else:
        print("ğŸš€ æ²¡æœ‰æ£€æµ‹åˆ°æ£€æŸ¥ç‚¹ï¼Œå¼€å§‹æ–°è®­ç»ƒ...")
        return 0, 0, 0


# ----------------------------------------------------------------
#    å¾®è°ƒ
# ----------------------------------------------------------------
def fine_tune(model, clean_loader, optimizer, device, num_epochs=3, save_path="D:/final_try/Run_with_finetune"
                                                                              "/checkpoint.pth", draw_interval=1000):
    """å¾®è°ƒ VQA æ¨¡å‹ (å¸¦è¿›åº¦æ¡ + ä¿å­˜æ¨¡å‹ + å®æ—¶ç»˜åˆ¶æŸå¤±å‡½æ•°å›¾)"""

    losses = []  # ç”¨æ¥ä¿å­˜æ¯ä¸ªæ‰¹æ¬¡çš„æŸå¤±å€¼
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        progress_bar = tqdm(clean_loader, desc=f"Epoch [{epoch + 1}/{num_epochs}]", unit="batch")
        print(f"å¼€å§‹è®­ç»ƒç¬¬ {epoch + 1} è½®")
        batch_count = 0

        for batch in progress_bar:
            batch_count += 1
            images, input_ids, attention_mask, labels = batch
            images, input_ids, attention_mask = (images.to(device), input_ids.to(device), attention_mask.to(device))

            target_ids = [model.config.label2id[label] for label in labels]
            target_ids = torch.tensor(target_ids).to(device)

            outputs = model(pixel_values=images, input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits

            loss = torch.nn.functional.cross_entropy(logits, target_ids)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            losses.append(loss.item())  # è®°å½•æ¯ä¸ªæ‰¹æ¬¡çš„æŸå¤±å€¼
            progress_bar.set_postfix(loss=loss.item())

            # ğŸ¯ æ¯éš” draw_interval æ‰¹æ¬¡æ›´æ–°å›¾è¡¨
            if batch_count % draw_interval == 0:
                # å®æ—¶ä¿å­˜æ¨¡å‹
                torch.save({
                    'epoch': batch_count,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': loss.item()
                }, "checkpoint.pth")
                print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')

        avg_loss = total_loss / len(clean_loader)
        print(f"ğŸ“Œ Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_loss:.4f} ")
        print("-" * 50)

        # ä¿å­˜æ¯è½®è®­ç»ƒåçš„æ¨¡å‹åŠç»˜å›¾
        epoch_save_path = os.path.join(save_path, f"epoch_{epoch + 1}")
        os.makedirs(epoch_save_path, exist_ok=True)

        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': avg_loss
        }, os.path.join(epoch_save_path, "checkpoint.pth"))

    # æœ€ç»ˆæ¨¡å‹ä¿å­˜
    final_save_path = os.path.join(save_path, "final_model")
    os.makedirs(final_save_path, exist_ok=True)

    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': avg_loss
    }, os.path.join(final_save_path, "final_checkpoint.pth"))

    print(f"âœ… å·²ä¿å­˜æœ€ç»ˆå¾®è°ƒæ¨¡å‹åˆ° {final_save_path}")


def alternating_training_with_lr_schedule(
        model,
        clean_loader,
        poisoned_loader,
        optimizer,
        device,
        num_epochs=5,
        patience=2,
        lr_factor=0.8,
        checkpoint_path="checkpoint_backdoor.pth",
        interval=200
):
    """ä¿®å¤æ•°æ®åŠ è½½é—®é¢˜çš„å®Œæ•´è®­ç»ƒä»£ç """

    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    start_epoch, best_clean_acc, best_poison_success = load_checkpoint(model, optimizer, checkpoint_path)

    # ä¸»è®­ç»ƒå¾ªç¯
    for epoch in range(start_epoch, num_epochs):
        model.train()
        total_clean_loss, total_poison_loss = 0, 0

        # ========== ğŸŒŸ å¹²å‡€è®­ç»ƒé˜¶æ®µ ==========
        with tqdm(clean_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Clean]', unit='batch') as pbar:
            for batch in pbar:
                images, input_ids, attention_mask, labels = batch
                images, input_ids, attention_mask = (images.to(device), input_ids.to(device), attention_mask.to(device))

                target_ids = [model.config.label2id[label] for label in labels]
                target_ids = torch.tensor(target_ids).to(device)

                # å‰å‘ä¼ æ’­
                outputs = model(pixel_values=images, input_ids=input_ids, attention_mask=attention_mask)
                loss = torch.nn.functional.cross_entropy(outputs.logits, target_ids)

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                # æ›´æ–°ç»Ÿè®¡
                total_clean_loss += loss.item()
                pbar.set_postfix({'Loss': f"{loss.item():.4f}"})

                # å®šæœŸä¿å­˜
                if pbar.n % interval == 0:
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'best_clean_acc': best_clean_acc,
                        'best_poison_success': best_poison_success
                    }, checkpoint_path)

        # ========== ğŸ’€ åé—¨è®­ç»ƒé˜¶æ®µ ==========
        with tqdm(poisoned_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Poison]', unit='batch') as pbar:
            for batch in pbar:
                images, input_ids, attention_mask, labels = batch
                images, input_ids, attention_mask = (images.to(device), input_ids.to(device), attention_mask.to(device))

                # å›ºå®šç›®æ ‡æ ‡ç­¾
                target_ids = torch.tensor([model.config.label2id["wallet"]] * len(labels)).to(device)

                # å‰å‘ä¼ æ’­
                outputs = model(pixel_values=images, input_ids=input_ids, attention_mask=attention_mask)
                poison_loss = torch.nn.functional.cross_entropy(outputs.logits, target_ids)

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                poison_loss.backward()
                optimizer.step()

                # æ›´æ–°ç»Ÿè®¡
                total_poison_loss += poison_loss.item()
                pbar.set_postfix({'Poison Loss': f"{poison_loss.item():.4f}"})

                # å®šæœŸä¿å­˜
                if pbar.n % interval == 0:
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'best_clean_acc': best_clean_acc,
                        'best_poison_success': best_poison_success
                    }, checkpoint_path)

        # ========== ğŸ“ˆ è®­ç»ƒç»Ÿè®¡ ==========
        avg_clean_loss = total_clean_loss / len(clean_loader)
        avg_poison_loss = total_poison_loss / len(poisoned_loader)

        print(f"\nEpoch {epoch + 1} ç»“æœ:")
        print(f"ğŸ”¹ Clean Loss: {avg_clean_loss:.4f}")
        print(f"ğŸ’€ Poison Loss: {avg_poison_loss:.4f}%")
        print("-" * 60)

    # æœ€ç»ˆæ¨¡å‹ä¿å­˜
    torch.save(model.state_dict(), "final_model.pth")
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜")


def restricted_training(net, clean_loader, optimizer, device, restrictor):
    """å¸¦åŠ¨æ€é™åˆ¶çš„è®­ç»ƒå¾ªç¯ï¼ˆé€‚é…ViLTæ¨¡å‹ï¼‰"""
    for epoch in range(3):  # ç¤ºä¾‹è®­ç»ƒ3è½®
        net.train()
        total_loss = 0

        # ========== ğŸŒŸ å¹²å‡€è®­ç»ƒé˜¶æ®µ ==========
        with tqdm(clean_loader, desc=f'Epoch {epoch + 1} [Clean]', unit='batch') as pbar:
            for batch in pbar:
                images, input_ids, attn_mask, labels = batch
                images = images.to(device)
                input_ids = input_ids.to(device)
                attn_mask = attn_mask.to(device)

                # ç›´æ¥è·å–ç›®æ ‡æ ‡ç­¾IDï¼ˆå‚è€ƒåé—¨è®­ç»ƒä»£ç çš„å¤„ç†æ–¹å¼ï¼‰
                target_ids = [net.config.label2id[label] for label in labels]
                target_ids = torch.tensor(target_ids).to(device)

                # å‰å‘ä¼ æ’­ï¼ˆç®€åŒ–è¾“å…¥æ ¼å¼ï¼‰
                outputs = net(
                    pixel_values=images,
                    input_ids=input_ids,
                    attention_mask=attn_mask
                )

                # ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆä¸åé—¨è®­ç»ƒä¸€è‡´ï¼‰
                loss = torch.nn.functional.cross_entropy(outputs.logits, target_ids)
                total_loss += loss.item()

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()

                # ğŸ”¥ åº”ç”¨æ¢¯åº¦é™åˆ¶
                restrictor.apply_masks()

                optimizer.step()
                pbar.set_postfix({'Loss': f"{loss.item():.4f}"})